{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import load_dataset, load_metric\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home2/likhithasapu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load custom dataset\n",
    "dataset = load_dataset('likhithasapu/codemix-annotated-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['data.idx', 'data.L1', 'data.L2', 'data.alignments', 'data.CM_candidates', 'data.CM_candidates_transliterated_indictrans', 'average_rating', 'int_annotations', 'LID', 'PoSTags'],\n",
       "        num_rows: 2145\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['data.idx', 'data.L1', 'data.L2', 'data.alignments', 'data.CM_candidates', 'data.CM_candidates_transliterated_indictrans', 'average_rating', 'int_annotations', 'LID', 'PoSTags'],\n",
       "        num_rows: 7507\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['data.idx', 'data.L1', 'data.L2', 'data.alignments', 'data.CM_candidates', 'data.CM_candidates_transliterated_indictrans', 'average_rating', 'int_annotations', 'LID', 'PoSTags'],\n",
       "        num_rows: 1073\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data.idx': [133401,\n",
       "  479708,\n",
       "  1697626,\n",
       "  405017,\n",
       "  1966633,\n",
       "  154465,\n",
       "  487741,\n",
       "  89372,\n",
       "  434991,\n",
       "  698315],\n",
       " 'data.L1': ['इनकी डेंगू की जांच भी करवाई जा रही है।',\n",
       "  'सवाल हिंदी और इंग्लिश दोनों में होंगे।',\n",
       "  'भारत ने अपनी टीम में एक बदलाव किया।',\n",
       "  'इस फ़िल्म में मुख्य भूमिका अक्षय कुमार निभा रहे हैं',\n",
       "  'हमें अगले मैच पर ध्यान लगाना होगा .',\n",
       "  'भारतीय लोक संस्कृति और समाज में गाय का सर्वोत्तम स्थान है।',\n",
       "  'गाने को तनिष्क बागची ने रिक्रिएट किया है .',\n",
       "  'कुछ देर के लिए सदन की कार्यवाही को रोकना पड़ा।',\n",
       "  'संजय दत्त को देखें , उन्होंने दुनिया के सामने कबूल किया .',\n",
       "  'कांग्रेस राज्य में सत्ता में है।'],\n",
       " 'data.L2': ['Their background checks are also being conducted .',\n",
       "  'the questions will be in English and Hindi .',\n",
       "  'India has made one change in the squad .',\n",
       "  'The film features Akshay Kumar in the lead role .',\n",
       "  'We focus on the next match .',\n",
       "  'Cows have a special place in Indian society and culture .',\n",
       "  'The song has been re-composed by Tanishk Bagchi .',\n",
       "  'The proceedings of the House was suspended for some time .',\n",
       "  'Look at Sanjay Dutt , he confessed to the world .',\n",
       "  'The Congress is in power in the state .'],\n",
       " 'data.alignments': ['0-0 2-1 3-2 4-4 5-6 6-5 7-5 8-7',\n",
       "  '0-1 1-7 2-6 3-5 4-5 5-4 6-2 6-3',\n",
       "  '0-0 1-1 1-2 3-7 4-5 5-3 6-4',\n",
       "  '0-2 1-0 1-1 2-5 3-6 3-7 4-8 5-3 6-4',\n",
       "  '0-0 1-4 2-5 3-2 3-3 4-1 5-1 7-6',\n",
       "  '0-6 1-9 2-9 3-8 4-7 5-5 6-0 7-3 9-4 10-1 10-2',\n",
       "  '0-1 1-0 2-6 3-7 4-5 5-3 5-4 6-2 7-2 8-8',\n",
       "  '0-8 1-8 1-9 2-7 3-7 4-4 5-2 6-1 7-0 8-6 9-5',\n",
       "  '0-2 1-3 2-7 3-0 3-1 4-4 5-5 6-9 7-8 8-6 9-6 11-10',\n",
       "  '0-1 1-7 2-3 2-5 3-4 4-3 5-2'],\n",
       " 'data.CM_candidates': ['Their background checks also conducted जा रही है।',\n",
       "  'the questions will be in हिंदी और इंग्लिश दोनों .',\n",
       "  'India has made एक बदलाव in the टीम .',\n",
       "  'The film features Akshay Kumar in मुख्य भूमिका .',\n",
       "  'हमें on the next match ध्यान लगाना .',\n",
       "  'Cows have a special place भारतीय culture और समाज में',\n",
       "  'The song Tanishk Bagchi ने रिक्रिएट किया है .',\n",
       "  'The proceedings of the House was suspended कुछ देर के लिए .',\n",
       "  'Look at Sanjay Dutt , उन्होंने confessed to दुनिया के .',\n",
       "  'The Congress in the state सत्ता में है।'],\n",
       " 'data.CM_candidates_transliterated_indictrans': ['Their background checks also conducted ja rahi he.',\n",
       "  'the questions will be in hindi or english donon .',\n",
       "  'India has made ek badlaav in the team .',\n",
       "  'The film features Akshay Kumar in mukhya bhoomika .',\n",
       "  'hamen on the next match dhyaan lagaana .',\n",
       "  'Cows have a special place bhartiya culture or samaaj main',\n",
       "  'The song Tanishk Bagchi ne ricreat kiya he .',\n",
       "  'The proceedings of the House was suspended kuch der ke liye .',\n",
       "  'Look at Sanjay Dutt , unhone confessed to duniya ke .',\n",
       "  'The Congress in the state satta main he.'],\n",
       " 'average_rating': [2.3333333333,\n",
       "  4.6666666667,\n",
       "  4.3333333333,\n",
       "  4.0,\n",
       "  3.3333333333,\n",
       "  4.6666666667,\n",
       "  4.3333333333,\n",
       "  3.6666666667,\n",
       "  2.6666666667,\n",
       "  4.0],\n",
       " 'int_annotations': [[2.0, 3.0, 2.0],\n",
       "  [4.0, 5.0, 5.0],\n",
       "  [4.0, 5.0, 4.0],\n",
       "  [4.0, 4.0, 4.0],\n",
       "  [4.0, 3.0, 3.0],\n",
       "  [4.0, 5.0, 5.0],\n",
       "  [3.0, 5.0, 5.0],\n",
       "  [4.0, 4.0, 3.0],\n",
       "  [3.0, 2.0, 3.0],\n",
       "  [5.0, 4.0, 3.0]],\n",
       " 'LID': [['en', 'en', 'en', 'en', 'en', 'hi', 'hi', 'hi'],\n",
       "  ['en', 'en', 'en', 'en', 'en', 'hi', 'hi', 'hi', 'hi', 'univ'],\n",
       "  ['ne', 'en', 'en', 'hi', 'hi', 'en', 'en', 'hi', 'univ'],\n",
       "  ['en', 'en', 'en', 'ne', 'ne', 'en', 'hi', 'hi', 'univ'],\n",
       "  ['hi', 'en', 'en', 'en', 'en', 'hi', 'hi', 'univ'],\n",
       "  ['en', 'en', 'en', 'en', 'en', 'hi', 'en', 'hi', 'hi', 'hi'],\n",
       "  ['en', 'en', 'ne', 'ne', 'hi', 'hi', 'hi', 'hi', 'univ'],\n",
       "  ['en', 'en', 'en', 'en', 'en', 'en', 'en', 'hi', 'hi', 'hi', 'hi', 'univ'],\n",
       "  ['en', 'en', 'ne', 'ne', 'univ', 'hi', 'en', 'en', 'hi', 'hi', 'univ'],\n",
       "  ['en', 'ne', 'en', 'en', 'en', 'hi', 'hi', 'hi']],\n",
       " 'PoSTags': [['PRON', 'NOUN', 'NOUN', 'ADV', 'VERB', 'AUX', 'AUX', 'AUX'],\n",
       "  ['DET',\n",
       "   'NOUN',\n",
       "   'AUX',\n",
       "   'AUX',\n",
       "   'ADP',\n",
       "   'PROPN',\n",
       "   'CCONJ',\n",
       "   'PROPN',\n",
       "   'PART',\n",
       "   'PUNCT'],\n",
       "  ['PROPN', 'AUX', 'VERB', 'NUM', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT'],\n",
       "  ['DET', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'ADP', 'ADJ', 'NOUN', 'PUNCT'],\n",
       "  ['PRON', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'VERB', 'PUNCT'],\n",
       "  ['NOUN',\n",
       "   'VERB',\n",
       "   'DET',\n",
       "   'ADJ',\n",
       "   'NOUN',\n",
       "   'ADJ',\n",
       "   'NOUN',\n",
       "   'CCONJ',\n",
       "   'NOUN',\n",
       "   'ADP'],\n",
       "  ['DET', 'NOUN', 'PROPN', 'PROPN', 'ADP', 'NOUN', 'VERB', 'AUX', 'PUNCT'],\n",
       "  ['DET',\n",
       "   'NOUN',\n",
       "   'ADP',\n",
       "   'DET',\n",
       "   'NOUN',\n",
       "   'AUX',\n",
       "   'VERB',\n",
       "   'DET',\n",
       "   'NOUN',\n",
       "   'ADP',\n",
       "   'ADP',\n",
       "   'PUNCT'],\n",
       "  ['VERB',\n",
       "   'ADP',\n",
       "   'PROPN',\n",
       "   'PROPN',\n",
       "   'PUNCT',\n",
       "   'PRON',\n",
       "   'VERB',\n",
       "   'ADP',\n",
       "   'NOUN',\n",
       "   'ADP',\n",
       "   'PUNCT'],\n",
       "  ['DET', 'PROPN', 'ADP', 'DET', 'NOUN', 'NOUN', 'ADP', 'AUX']]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer and Model\n",
    "model_name = 'ai4bharat/indic-bert'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)  # Adjust num_labels based on your labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and preprocessing\n",
    "def preprocess_function(examples):\n",
    "    # Use 'average_rating' directly for regression\n",
    "    labels = np.array(examples['average_rating'])\n",
    "    # Tokenize the 'data.L1' text\n",
    "    tokenized_input = tokenizer(examples['data.CM_candidates'], truncation=True)\n",
    "    return {**tokenized_input, 'labels': labels}\n",
    "\n",
    "# Apply preprocessing and remove columns\n",
    "processed_datasets = dataset.map(preprocess_function, batched=True, remove_columns=dataset['test'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 27750, 32, 18, 496, 297, 8007, 70, 524, 487, 2092, 5, 3],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': 4.3333333333}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_datasets['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Define TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    evaluation_strategy=\"epoch\",     # evaluation strategy\n",
    "    learning_rate=2e-5,               # learning rate\n",
    "    per_device_train_batch_size=8,   # batch size for training\n",
    "    per_device_eval_batch_size=8,    # batch size for evaluation\n",
    "    num_train_epochs=10,              # number of epochs\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    save_total_limit=1,              # limit the total amount of checkpoints\n",
    "    save_strategy='epoch',           # save the model after each epoch\n",
    "    load_best_model_at_end=True, \n",
    "    metric_for_best_model='rmse'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_datasets['train'],\n",
    "    eval_dataset=processed_datasets['test'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlikhithasapu\u001b[0m (\u001b[33mcmacc\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/likhithasapu/pun/wandb/run-20240725_224104-2tw5grjr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cmacc/huggingface/runs/2tw5grjr' target=\"_blank\">gallant-snow-144</a></strong> to <a href='https://wandb.ai/cmacc/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cmacc/huggingface' target=\"_blank\">https://wandb.ai/cmacc/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cmacc/huggingface/runs/2tw5grjr' target=\"_blank\">https://wandb.ai/cmacc/huggingface/runs/2tw5grjr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4700' max='4700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4700/4700 07:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.784629</td>\n",
       "      <td>0.885793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.348600</td>\n",
       "      <td>0.627635</td>\n",
       "      <td>0.792234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>0.639771</td>\n",
       "      <td>0.799857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.426700</td>\n",
       "      <td>0.682592</td>\n",
       "      <td>0.826191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.257200</td>\n",
       "      <td>0.711185</td>\n",
       "      <td>0.843318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>0.696518</td>\n",
       "      <td>0.834576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.684776</td>\n",
       "      <td>0.827512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.699496</td>\n",
       "      <td>0.836359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.692598</td>\n",
       "      <td>0.832225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.691912</td>\n",
       "      <td>0.831813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home2/likhithasapu/miniconda3/envs/research/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4700, training_loss=0.3203004168956838, metrics={'train_runtime': 438.7694, 'train_samples_per_second': 171.092, 'train_steps_per_second': 10.712, 'total_flos': 63999744125310.0, 'train_loss': 0.3203004168956838, 'epoch': 10.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer.json:   0%|          | 0.00/15.3M [00:00<?, ?B/s]\n",
      "tokenizer.json:   0%|          | 16.4k/15.3M [00:00<02:43, 93.6kB/s]\n",
      "tokenizer.json:  11%|█         | 1.61M/15.3M [00:00<00:02, 6.09MB/s]\n",
      "\u001b[A\n",
      "tokenizer.json:  15%|█▍        | 2.28M/15.3M [00:00<00:06, 2.08MB/s]\n",
      "tokenizer.json:  18%|█▊        | 2.69M/15.3M [00:01<00:05, 2.35MB/s]\n",
      "tokenizer.json: 100%|██████████| 15.3M/15.3M [00:02<00:00, 6.52MB/s]\n",
      "spiece.model: 100%|██████████| 5.65M/5.65M [00:02<00:00, 2.00MB/s]\n",
      "Upload 2 LFS files: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]\n",
      "model.safetensors: 100%|██████████| 134M/134M [00:15<00:00, 8.80MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/likhithasapu/indic-bert-regression-v1/commit/311c23a43e96975334b88754218a822eeed88f02', commit_message='Upload AlbertForSequenceClassification', commit_description='', oid='311c23a43e96975334b88754218a822eeed88f02', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model to hub\n",
    "tokenizer.push_to_hub(\"likhithasapu/indic-bert-regression-v1\")\n",
    "model.push_to_hub(\"likhithasapu/indic-bert-regression-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4797494411468506"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference code\n",
    "def predict(text):\n",
    "    tokenized_input = tokenizer(text, truncation=True, padding=True, return_tensors='pt').to(model.device)\n",
    "    return model(**tokenized_input).logits.item()\n",
    "\n",
    "predict(\"यही बात is नही to the हज़म of कांग्रेस .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
